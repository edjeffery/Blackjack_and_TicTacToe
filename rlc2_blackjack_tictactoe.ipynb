{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CM 50270 Reinforcement Learning: Coursework 2 \n",
    "\n",
    "**Date set:** March 12, 2018 \n",
    "\n",
    "**Date due:** 8 pm on March 21, 2018 \n",
    "\n",
    "**Total number of marks:** 100. (This coursework will determine 20% of your final grade for CM 50270.)\n",
    "\n",
    "**What to submit:** Completed Jupyter notebook (.ipynb file) that includes all source code. Please do not change the file name.\n",
    "\n",
    "**Where to submit:** CM50270 Moodle page\n",
    "\n",
    "This coursework will be __marked anonymously__. Please do not include any identifying information on the files you submit. \n",
    "\n",
    "You are required to __work individually__. You are welcome to discuss ideas with others but you must design your own implementation and write your own code.\n",
    "\n",
    "__Do not plagiarise__. Plagiarism is a serious academic offence. For details on what it is and how to avoid it, please visit the following webpage: http://www.bath.ac.uk/library/help/infoguides/plagiarism.html\n",
    "\n",
    "Restart the kernel and run all cells before submitting the notebook. This will guarantee that we will be able to run your code for testing.\n",
    "\n",
    "Remember to save your work regularly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Blackjack (20 marks)\n",
    "\n",
    "In this first exercise, you will implement **Monte Carlo Policy Evaluation (MCPE)** to learn the state-value function $V(s)$ for a given policy in the game of [blackjack](https://en.wikipedia.org/wiki/Blackjack)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The game\n",
    "\n",
    "**Rules.** We will use the version of the game discussed in the lectures where a single player (the agent) plays against the dealer. The player's objective is to obtain cards whose sum is as large as possible without exceeding 21. All face cards count as 10; an ace can count as either 1 or 11.\n",
    "\n",
    "The game begins with two cards dealt to both the dealer and the player. The first of the dealer’s cards is face down and the second is face up. If the player has 21 immediately (for example, an ace and a face card), it is called a \"blackjack\". The player then wins unless the dealer also has a blackjack, in which case the game is a draw. If the player does not have a blackjack, then she can request additional cards, one by one (_hits_), until she either stops (_sticks_) or exceeds 21 (_goes bust_). If the player goes bust, she loses; if she sticks, then it becomes the dealer’s turn. \n",
    "\n",
    "The dealer hits or sticks according to a fixed strategy without choice: he sticks on any sum of 17 or greater, hits otherwise. If the dealer goes bust, then the player wins; otherwise, the outcome (win, lose, or draw) is determined by whose final sum is closer to 21.\n",
    "\n",
    "**MDP formulation.** Playing blackjack is naturally formulated as an episodic finite MDP. Each game of blackjack is an episode. Rewards of +1, −1, and 0 are given for winning, losing, and drawing, respectively. All rewards until the end of the game are zero. We do not discount ($\\gamma = 1$); therefore these terminal rewards are also the returns. The player’s actions are to `\"hit\"` or to `\"stick\"`. \n",
    "\n",
    "The states depend on the player’s cards and the dealer’s showing card. Assume that cards are dealt from an infinite deck (that is, with replacement) so that there is no advantage to keeping track of the cards already dealt. If the player holds an ace that she could count as 11 without going bust, then the ace is said to be _usable_. In this case it is always counted as 11 because counting it as 1 would make the sum 11 or less, in which case there is no decision to be made because, obviously, the player should always hit. Thus, the player makes decisions on the basis of three variables: \n",
    "- the player's current sum (an integer between 12 and 21);\n",
    "- the dealer’s one showing card (an integer between 1 and 10; note that the ace is counted as 1 here); and\n",
    "- whether or not the player holds a usable ace (a boolean). \n",
    "\n",
    "This makes for a total of 200 states. We represent the state as a numpy-array of length 3 that combines the just mentioned three variables in the given order. For example, if the player is given a 6 and a _jack_, and the dealer's showing card is an ace, the corresponding state will be the numpy array `[16, 1, False]`. The terminal state of the game will be denoted by the numpy array `[-1, -1, -1]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Blackjack code you may use if you wish\n",
    "\n",
    "** Please feel free to skip this section and implement your own blackjack code **\n",
    "\n",
    "We provide a `Blackjack` class that you can use to simulate blackjack games. The following cells in this section will walk you through the basic usage of this class by playing a couple of blackjack games.  \n",
    "\n",
    "We import the blackjack module and create a blackjack environmnet called `env`. The constructor method has one argument called `verbose`. If `verbose=True`, the blackjack object will regularly print the progress of the game. This is useful for getting to know the game and the provided code or if you just want to play around. You may want to set `verbose=False` when you run thousands of episodes to complete the exercise below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import blackjack\n",
    "env = blackjack.Blackjack(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can interact with the blackjack environment using the `make_step()` method. This method takes an `action` as input and computes the response of the environment. Specifically, this method returns the resulting `new_state` and the corresponding `reward` signal.\n",
    "\n",
    "Before the player can perform actions, we have to start the game (e.g., draw starting hands). In order to start or reset a blackjack game, call the `make_step()` without specifying a specific action or by setting `action=\"reset\"`.\n",
    "\n",
    "We will now walk through several example games. We will specify a [random seed](https://en.wikipedia.org/wiki/Random_seed) for the NumPy pseudo random number generator every time before we reset the game. This allows us to keep these examples reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The game is reset.\n",
      "Player's cards: [10, 10]\n",
      "Dealer's showing card: [7]\n",
      "Initial state: [20  7  0]\n",
      "Reward: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(8)\n",
    "new_state, reward = env.make_step(action=\"reset\")\n",
    "print(\"Initial state:\", new_state)\n",
    "print(\"Reward:\", reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The player drew two cards with face value 10 each. The dealer also drew two cards, but we can only see the second card, a 7. The player now can choose to \"hit\" or \"stick\". Most players would stick if they had 20 on their hand. We call again the `make_step()` method and specify `action=\"stick\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dealer's cards are: [10, 7]\n",
      "The dealer has 17 points.\n",
      "PLAYER WINS!\n",
      "The player obtains a reward of 1\n",
      "The new (terminal) state is: [-1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "new_state, reward = env.make_step(action = \"stick\")\n",
    "print(\"The player obtains a reward of\", reward)\n",
    "print(\"The new (terminal) state is:\", new_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The player won and received a reward of 1. Whenever an episode ends, the environment object sets the internal variable `self.active` to `False`. This variable is set to `True` again when we _reset_ the game. You can use the `self.active` variable to check whether an episode has ended or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The game is reset.\n",
      "Player's cards: [11, 7]\n",
      "Dealer's showing card: [2]\n",
      "New state: [18  2  1]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(9)\n",
    "new_state, reward = env.make_step(action=\"reset\")\n",
    "print(\"New state:\", new_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The player has already 18 points but has a _usable ace_, which she can transfer into a 1 whenever she would _go bust_. The player can thus \"hit\" and hope that she gets closer to 21. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player draws card: [2]\n",
      "New sum of player's cards: [20]\n"
     ]
    }
   ],
   "source": [
    "new_state, reward = env.make_step(action = \"hit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! The player got another 2 points and has again 20 points. The player would probably want to \"stick\" again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dealer's cards are: [7, 2]\n",
      "The dealer has 9 points.\n",
      "Dealer draws card: [3]\n",
      "New dealer sum [12]\n",
      "Dealer draws card: [6]\n",
      "New dealer sum [18]\n",
      "PLAYER WINS!\n"
     ]
    }
   ],
   "source": [
    "new_state, reward = env.make_step(action = \"stick\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The player won again! Let's play a last one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The game is reset.\n",
      "Player's cards: [11, 10]\n",
      "Dealer's showing card: [10]\n",
      "Player has Blackjack!\n",
      "The dealer's cards are: [6, 10]\n",
      "PLAYER WINS!\n",
      "Reward: 1\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(7)\n",
    "new_state, reward = env.make_step()\n",
    "print(\"Reward:\", reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The player drew a \"Blackjack\", that is, an ace and a 10. The dealer's cards valued 16. The player won again and received a reward without having performed an action. Try out some more games to get familiar with the code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "Your task is to learn the state-value function for the policy **\"Stick if the player's sum is 19 or higher, and hit otherwise.\"**. Your code should compute these state values using **Monte Carlo Policy Evaluation (MCPE)**. For your reference, the pseudo-code for MCPE is reproduced below from the textbook (Reinforcement Learning, Sutton & Barto, 1998, Section 5.1).\n",
    "<img src=\"images/MCPE.png\" style=\"width: 400px;\"/>\n",
    "The provided pseudo-code shows _first-visit_ MCPE. No state occurs twice during one game (episode) of Blackjack. In this case, first-visit MCPE and every-visit MCPE are identical.\n",
    "\n",
    "You will have to provide a function `get_state_value(s, v)` that takes as input a state `s` (a numpy array of length 3 as described in the MDP formulation of blackjack) and the state values `v` that you computed. The `get_state_value(s, v)` should return the correponding state value $V(s)$ as a float. There are no restrictions on how you store the state values `v`.\n",
    "\n",
    "We will mark your code by calling `get_state_value(s, v)` for different states valid states `s` in the _test cell_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7051cb2b547a6f02d56440d85ed9d198",
     "grade": false,
     "grade_id": "cell-a46757fc05631afe",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State:  (12, 1, 0) \tValue:  -0.41935483870967744\n",
      "State:  (12, 1, 1) \tValue:  0.0\n",
      "State:  (12, 2, 0) \tValue:  -0.35789473684210527\n",
      "State:  (12, 2, 1) \tValue:  0.0\n",
      "State:  (12, 3, 0) \tValue:  -0.3854166666666667\n",
      "State:  (12, 3, 1) \tValue:  0.0\n",
      "State:  (12, 4, 0) \tValue:  -0.308411214953271\n",
      "State:  (12, 4, 1) \tValue:  0.0\n",
      "State:  (12, 5, 0) \tValue:  -0.2926829268292683\n",
      "State:  (12, 5, 1) \tValue:  0.0\n",
      "State:  (12, 6, 0) \tValue:  -0.3125\n",
      "State:  (12, 6, 1) \tValue:  0.0\n",
      "State:  (12, 7, 0) \tValue:  -0.18085106382978725\n",
      "State:  (12, 7, 1) \tValue:  0.0\n",
      "State:  (12, 8, 0) \tValue:  -0.32051282051282054\n",
      "State:  (12, 8, 1) \tValue:  0.0\n",
      "State:  (12, 9, 0) \tValue:  -0.2882882882882883\n",
      "State:  (12, 9, 1) \tValue:  0.0\n",
      "State:  (12, 10, 0) \tValue:  -0.2784090909090909\n",
      "State:  (12, 10, 1) \tValue:  0.0\n",
      "State:  (13, 1, 0) \tValue:  -0.4482758620689655\n",
      "State:  (13, 1, 1) \tValue:  0.0\n",
      "State:  (13, 2, 0) \tValue:  -0.4574468085106383\n",
      "State:  (13, 2, 1) \tValue:  0.0\n",
      "State:  (13, 3, 0) \tValue:  -0.40425531914893614\n",
      "State:  (13, 3, 1) \tValue:  0.0\n",
      "State:  (13, 4, 0) \tValue:  -0.2926829268292683\n",
      "State:  (13, 4, 1) \tValue:  0.0\n",
      "State:  (13, 5, 0) \tValue:  -0.3333333333333333\n",
      "State:  (13, 5, 1) \tValue:  0.0\n",
      "State:  (13, 6, 0) \tValue:  -0.3977272727272727\n",
      "State:  (13, 6, 1) \tValue:  0.0\n",
      "State:  (13, 7, 0) \tValue:  -0.4090909090909091\n",
      "State:  (13, 7, 1) \tValue:  0.0\n",
      "State:  (13, 8, 0) \tValue:  -0.5\n",
      "State:  (13, 8, 1) \tValue:  0.0\n",
      "State:  (13, 9, 0) \tValue:  -0.47959183673469385\n",
      "State:  (13, 9, 1) \tValue:  0.0\n",
      "State:  (13, 10, 0) \tValue:  -0.4065040650406504\n",
      "State:  (13, 10, 1) \tValue:  0.0\n",
      "State:  (14, 1, 0) \tValue:  -0.5\n",
      "State:  (14, 1, 1) \tValue:  0.0\n",
      "State:  (14, 2, 0) \tValue:  -0.4148936170212766\n",
      "State:  (14, 2, 1) \tValue:  0.0\n",
      "State:  (14, 3, 0) \tValue:  -0.4583333333333333\n",
      "State:  (14, 3, 1) \tValue:  0.0\n",
      "State:  (14, 4, 0) \tValue:  -0.4666666666666667\n",
      "State:  (14, 4, 1) \tValue:  0.0\n",
      "State:  (14, 5, 0) \tValue:  -0.4583333333333333\n",
      "State:  (14, 5, 1) \tValue:  0.0\n",
      "State:  (14, 6, 0) \tValue:  -0.3804347826086957\n",
      "State:  (14, 6, 1) \tValue:  0.0\n",
      "State:  (14, 7, 0) \tValue:  -0.49\n",
      "State:  (14, 7, 1) \tValue:  0.0\n",
      "State:  (14, 8, 0) \tValue:  -0.5061728395061729\n",
      "State:  (14, 8, 1) \tValue:  0.0\n",
      "State:  (14, 9, 0) \tValue:  -0.4953271028037383\n",
      "State:  (14, 9, 1) \tValue:  0.0\n",
      "State:  (14, 10, 0) \tValue:  -0.4740740740740741\n",
      "State:  (14, 10, 1) \tValue:  0.0\n",
      "State:  (15, 1, 0) \tValue:  -0.45348837209302323\n",
      "State:  (15, 1, 1) \tValue:  0.0\n",
      "State:  (15, 2, 0) \tValue:  -0.54\n",
      "State:  (15, 2, 1) \tValue:  0.0\n",
      "State:  (15, 3, 0) \tValue:  -0.5392156862745098\n",
      "State:  (15, 3, 1) \tValue:  0.0\n",
      "State:  (15, 4, 0) \tValue:  -0.4791666666666667\n",
      "State:  (15, 4, 1) \tValue:  0.0\n",
      "State:  (15, 5, 0) \tValue:  -0.4857142857142857\n",
      "State:  (15, 5, 1) \tValue:  0.0\n",
      "State:  (15, 6, 0) \tValue:  -0.54\n",
      "State:  (15, 6, 1) \tValue:  0.0\n",
      "State:  (15, 7, 0) \tValue:  -0.5789473684210527\n",
      "State:  (15, 7, 1) \tValue:  0.0\n",
      "State:  (15, 8, 0) \tValue:  -0.5494505494505495\n",
      "State:  (15, 8, 1) \tValue:  0.0\n",
      "State:  (15, 9, 0) \tValue:  -0.5638297872340425\n",
      "State:  (15, 9, 1) \tValue:  0.0\n",
      "State:  (15, 10, 0) \tValue:  -0.5241730279898219\n",
      "State:  (15, 10, 1) \tValue:  0.0\n",
      "State:  (16, 1, 0) \tValue:  -0.631578947368421\n",
      "State:  (16, 1, 1) \tValue:  0.0\n",
      "State:  (16, 2, 0) \tValue:  -0.5977011494252874\n",
      "State:  (16, 2, 1) \tValue:  0.0\n",
      "State:  (16, 3, 0) \tValue:  -0.5333333333333333\n",
      "State:  (16, 3, 1) \tValue:  0.0\n",
      "State:  (16, 4, 0) \tValue:  -0.7155963302752294\n",
      "State:  (16, 4, 1) \tValue:  0.0\n",
      "State:  (16, 5, 0) \tValue:  -0.5172413793103449\n",
      "State:  (16, 5, 1) \tValue:  0.0\n",
      "State:  (16, 6, 0) \tValue:  -0.6346153846153846\n",
      "State:  (16, 6, 1) \tValue:  0.0\n",
      "State:  (16, 7, 0) \tValue:  -0.616822429906542\n",
      "State:  (16, 7, 1) \tValue:  0.0\n",
      "State:  (16, 8, 0) \tValue:  -0.5666666666666667\n",
      "State:  (16, 8, 1) \tValue:  0.0\n",
      "State:  (16, 9, 0) \tValue:  -0.69\n",
      "State:  (16, 9, 1) \tValue:  0.0\n",
      "State:  (16, 10, 0) \tValue:  -0.6100478468899522\n",
      "State:  (16, 10, 1) \tValue:  0.0\n",
      "State:  (17, 1, 0) \tValue:  -0.6548672566371682\n",
      "State:  (17, 1, 1) \tValue:  0.0\n",
      "State:  (17, 2, 0) \tValue:  -0.6224489795918368\n",
      "State:  (17, 2, 1) \tValue:  0.0\n",
      "State:  (17, 3, 0) \tValue:  -0.6764705882352942\n",
      "State:  (17, 3, 1) \tValue:  0.0\n",
      "State:  (17, 4, 0) \tValue:  -0.6578947368421053\n",
      "State:  (17, 4, 1) \tValue:  0.0\n",
      "State:  (17, 5, 0) \tValue:  -0.6410256410256411\n",
      "State:  (17, 5, 1) \tValue:  0.0\n",
      "State:  (17, 6, 0) \tValue:  -0.7\n",
      "State:  (17, 6, 1) \tValue:  0.0\n",
      "State:  (17, 7, 0) \tValue:  -0.8\n",
      "State:  (17, 7, 1) \tValue:  0.0\n",
      "State:  (17, 8, 0) \tValue:  -0.6477272727272727\n",
      "State:  (17, 8, 1) \tValue:  0.0\n",
      "State:  (17, 9, 0) \tValue:  -0.696078431372549\n",
      "State:  (17, 9, 1) \tValue:  0.0\n",
      "State:  (17, 10, 0) \tValue:  -0.6829896907216495\n",
      "State:  (17, 10, 1) \tValue:  0.0\n",
      "State:  (18, 1, 0) \tValue:  -0.8181818181818182\n",
      "State:  (18, 1, 1) \tValue:  0.0\n",
      "State:  (18, 2, 0) \tValue:  -0.71900826446281\n",
      "State:  (18, 2, 1) \tValue:  0.0\n",
      "State:  (18, 3, 0) \tValue:  -0.7238095238095238\n",
      "State:  (18, 3, 1) \tValue:  0.0\n",
      "State:  (18, 4, 0) \tValue:  -0.8018867924528302\n",
      "State:  (18, 4, 1) \tValue:  0.0\n",
      "State:  (18, 5, 0) \tValue:  -0.7657657657657657\n",
      "State:  (18, 5, 1) \tValue:  0.0\n",
      "State:  (18, 6, 0) \tValue:  -0.719626168224299\n",
      "State:  (18, 6, 1) \tValue:  0.0\n",
      "State:  (18, 7, 0) \tValue:  -0.7678571428571429\n",
      "State:  (18, 7, 1) \tValue:  0.0\n",
      "State:  (18, 8, 0) \tValue:  -0.7226277372262774\n",
      "State:  (18, 8, 1) \tValue:  0.0\n",
      "State:  (18, 9, 0) \tValue:  -0.7238095238095238\n",
      "State:  (18, 9, 1) \tValue:  0.0\n",
      "State:  (18, 10, 0) \tValue:  -0.7881548974943052\n",
      "State:  (18, 10, 1) \tValue:  0.0\n",
      "State:  (19, 1, 0) \tValue:  -0.11578947368421053\n",
      "State:  (19, 1, 1) \tValue:  -0.10526315789473684\n",
      "State:  (19, 2, 0) \tValue:  0.4117647058823529\n",
      "State:  (19, 2, 1) \tValue:  0.15\n",
      "State:  (19, 3, 0) \tValue:  0.5054945054945055\n",
      "State:  (19, 3, 1) \tValue:  0.6\n",
      "State:  (19, 4, 0) \tValue:  0.39285714285714285\n",
      "State:  (19, 4, 1) \tValue:  0.36363636363636365\n",
      "State:  (19, 5, 0) \tValue:  0.42276422764227645\n",
      "State:  (19, 5, 1) \tValue:  0.631578947368421\n",
      "State:  (19, 6, 0) \tValue:  0.6041666666666666\n",
      "State:  (19, 6, 1) \tValue:  0.2857142857142857\n",
      "State:  (19, 7, 0) \tValue:  0.6814159292035398\n",
      "State:  (19, 7, 1) \tValue:  0.6428571428571429\n",
      "State:  (19, 8, 0) \tValue:  0.5\n",
      "State:  (19, 8, 1) \tValue:  0.5217391304347826\n",
      "State:  (19, 9, 0) \tValue:  0.21311475409836064\n",
      "State:  (19, 9, 1) \tValue:  0.2857142857142857\n",
      "State:  (19, 10, 0) \tValue:  0.021634615384615384\n",
      "State:  (19, 10, 1) \tValue:  0.10714285714285714\n",
      "State:  (20, 1, 0) \tValue:  0.008403361344537815\n",
      "State:  (20, 1, 1) \tValue:  0.4444444444444444\n",
      "State:  (20, 2, 0) \tValue:  0.7161290322580646\n",
      "State:  (20, 2, 1) \tValue:  0.5454545454545454\n",
      "State:  (20, 3, 0) \tValue:  0.5952380952380952\n",
      "State:  (20, 3, 1) \tValue:  0.8823529411764706\n",
      "State:  (20, 4, 0) \tValue:  0.7397260273972602\n",
      "State:  (20, 4, 1) \tValue:  0.6538461538461539\n",
      "State:  (20, 5, 0) \tValue:  0.6617647058823529\n",
      "State:  (20, 5, 1) \tValue:  0.8636363636363636\n",
      "State:  (20, 6, 0) \tValue:  0.7253521126760564\n",
      "State:  (20, 6, 1) \tValue:  0.6923076923076923\n",
      "State:  (20, 7, 0) \tValue:  0.8666666666666667\n",
      "State:  (20, 7, 1) \tValue:  0.6111111111111112\n",
      "State:  (20, 8, 0) \tValue:  0.835820895522388\n",
      "State:  (20, 8, 1) \tValue:  0.7692307692307693\n",
      "State:  (20, 9, 0) \tValue:  0.7213114754098361\n",
      "State:  (20, 9, 1) \tValue:  0.5833333333333334\n",
      "State:  (20, 10, 0) \tValue:  0.4234875444839858\n",
      "State:  (20, 10, 1) \tValue:  0.3787878787878788\n",
      "State:  (21, 1, 0) \tValue:  0.7346938775510204\n",
      "State:  (21, 1, 1) \tValue:  0.8\n",
      "State:  (21, 2, 0) \tValue:  0.86\n",
      "State:  (21, 2, 1) \tValue:  1.0\n",
      "State:  (21, 3, 0) \tValue:  0.8260869565217391\n",
      "State:  (21, 3, 1) \tValue:  0.6\n",
      "State:  (21, 4, 0) \tValue:  0.8909090909090909\n",
      "State:  (21, 4, 1) \tValue:  0.6666666666666666\n",
      "State:  (21, 5, 0) \tValue:  0.8947368421052632\n",
      "State:  (21, 5, 1) \tValue:  0.8571428571428571\n",
      "State:  (21, 6, 0) \tValue:  0.8392857142857143\n",
      "State:  (21, 6, 1) \tValue:  1.0\n",
      "State:  (21, 7, 0) \tValue:  0.9\n",
      "State:  (21, 7, 1) \tValue:  1.0\n",
      "State:  (21, 8, 0) \tValue:  0.9333333333333333\n",
      "State:  (21, 8, 1) \tValue:  1.0\n",
      "State:  (21, 9, 0) \tValue:  0.9803921568627451\n",
      "State:  (21, 9, 1) \tValue:  0.6666666666666666\n",
      "State:  (21, 10, 0) \tValue:  0.8789237668161435\n",
      "State:  (21, 10, 1) \tValue:  0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# This cell should compute the state values 'v' using MCPE.\n",
    "import blackjack\n",
    "\n",
    "env = blackjack.Blackjack(verbose=False)\n",
    "\n",
    "def policy(state):\n",
    "    if state[0] >= 19:\n",
    "        action = \"stick\"\n",
    "    else:\n",
    "        action = \"hit\"\n",
    "    return action\n",
    "\n",
    "num_episodes = 10000\n",
    "\n",
    "v = {}\n",
    "\n",
    "for player_sum in range(12, 22):\n",
    "    for dealer_sum in range(1, 11):\n",
    "        for usable_ace in range(0, 2):\n",
    "            v[(player_sum, dealer_sum, usable_ace)] = 0\n",
    "\n",
    "#print(len(v))\n",
    "#print(v)\n",
    "\n",
    "rewards = v.copy()\n",
    "visited_states = v.copy()\n",
    "\n",
    "for episode in range(1, num_episodes + 1):\n",
    "    state, _ = env.make_step(action=\"reset\")\n",
    "    while state[0] != -1:\n",
    "        action = policy(state)\n",
    "        new_state, reward = env.make_step(action)\n",
    "        rewards[tuple(state)] += reward\n",
    "        visited_states[tuple(state)] += 1\n",
    "        state = new_state\n",
    " \n",
    "#print(rewards)\n",
    "#print(visited_states)\n",
    "\n",
    "for key, value in v.items():\n",
    "    v[key] = rewards[key] / visited_states[key]\n",
    "for key, value in v.items():\n",
    "    print(\"State: \", key, \"\\tValue: \", value)\n",
    "    \n",
    "#print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "348e28b866f0bc3d77e4ddd1a3c726ee",
     "grade": false,
     "grade_id": "cell-cddecbc6ed38c8c8",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.835820895522388\n"
     ]
    }
   ],
   "source": [
    "# Complete the function definition for get_state_value(s,v) in this cell.\n",
    "def get_state_value(s, v):\n",
    "    \n",
    "    state = tuple(s)\n",
    "    value_of_s = v[state]\n",
    "    \n",
    "    return value_of_s\n",
    "\n",
    "print(get_state_value([20,8,0], v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "adda36d51c2da2acf4620abdcc6d3d6f",
     "grade": true,
     "grade_id": "cell-3345547d747d76e4",
     "locked": true,
     "points": 20,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This is the TEST CELL for Exercise 1. We will use it to mark your solution. \n",
    "# All of your code for Exercise 1 must be written above this cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Tic-Tac-Toe (80 marks)\n",
    "\n",
    "In this exercise you will implement the game of [Tic-Tac-Toe](https://en.wikipedia.org/wiki/Tic-tac-toe) (also known as _noughts and crosses_) and learn an optimal policy using **Q-learning**. You will then implement **SARSA** and compare the two learning approaches with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The game\n",
    "\n",
    "Tic-Tac-Toe is a paper-and-pencil game for two players, O and X, who take turns marking the spaces in a 3×3 grid. The player who succeeds in placing three of their marks in a horizontal, vertical, or diagonal row wins the game. The following example game is won by player X (example from [Wikipedia](https://en.wikipedia.org/wiki/Tic-tac-toe)):\n",
    "<img src=\"images/tic-tac-toe_WIKI.png\" style=\"width: 600px;\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "Implement the game of Tic-Tac-Toe. The first-moving player is randomly chosen at the beginning of each episode. Rewards of +1, −1, and 0 are given for winning, losing, and drawing, respectively. All rewards within a game are zero; do not discount ($\\gamma = 1$). Player X will always be played by a _random agent_. This agent randomly chooses one of the empty grid spaces and marks it with \"X\". You will implement different agents for Player O.\n",
    "\n",
    "We will ask you to plot your results and to discuss the produced plots. Please make sure to **label your figures appropriately**. Please only use plotting packages that come pre-installed with Anaconda 3. We recommend the package `matplotlib` (the tutorial provided in the first lab contains a whole section on matplotlib)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2a: Random policy against a random policy (10 marks)\n",
    "Test your Tic-Tac-Toe implementation by letting two random agents play against each other. Plot the cumulative rewards of both O and X as a function of the number of episodes played. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEKCAYAAAAMzhLIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDMMwjCf/D+Bqmb8KQn0KAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e95c898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Your code for Exercise 2a\n",
    "import random\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "class Tictactoe():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.players = {\"O\": 1, \"X\": 2}\n",
    "        self.winners = np.array([\n",
    "            [0, 1, 2], [3, 4, 5], [6, 7, 8],\n",
    "            [0, 3, 6], [1, 4, 7], [2, 5, 8],\n",
    "            [0, 4, 8], [2, 4, 6]\n",
    "            ])\n",
    "        self.board = self.create_board()\n",
    "\n",
    "    def create_board(self):\n",
    "        return np.zeros(9, dtype=int)\n",
    "\n",
    "    def print_board(self):\n",
    "        b = np.reshape(self.board, (3,3))\n",
    "        print(b)\n",
    "\n",
    "    def choose_move(self):\n",
    "        valid_moves = []\n",
    "\n",
    "        for i in range(9):\n",
    "            if self.board[i] == 0:\n",
    "                valid_moves.append(i)\n",
    "        \n",
    "        move = random.choice(valid_moves)\n",
    "        return move\n",
    "\n",
    "    def make_move(self, player, move):\n",
    "        piece = self.players[player]\n",
    "        #print(piece)\n",
    "        self.board[move] = piece\n",
    "\n",
    "    def check_win(self):\n",
    "        for _, player in self.players.items():\n",
    "            for row in self.winners:\n",
    "                if all([self.board[cell] == player for cell in row]):\n",
    "                    return player\n",
    "\n",
    "        for i in range(9):\n",
    "            if self.board[i] == 0:\n",
    "                return None # No one has won yet\n",
    "\n",
    "        # Otherwise, game is a draw\n",
    "        return 0\n",
    "\n",
    "    def play(self):\n",
    "        #board = create_board()\n",
    "        #print_board(board)\n",
    "        p = list(self.players.items())\n",
    "        random.shuffle(p)\n",
    "        #print(p[0])\n",
    "        for player, _ in itertools.cycle(p):\n",
    "            move = self.choose_move()\n",
    "            self.make_move(player, move)\n",
    "            winner = self.check_win()\n",
    "            if winner != None:\n",
    "                #if winner == 0:\n",
    "                    # Game is a draw\n",
    "                    #print(\"Game is a draw\")\n",
    "                #elif winner == 1:\n",
    "                    #print(\"Player O wins\")\n",
    "                #elif winner == 2:\n",
    "                    #print(\"Player X wins\")\n",
    "                #print(winner)\n",
    "                return winner\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "num_episodes = 5000\n",
    "\n",
    "results_O = np.zeros(num_episodes)\n",
    "results_X = np.zeros(num_episodes)\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    t = Tictactoe()\n",
    "    result = t.play()\n",
    "    #print(t.board)\n",
    "    if result == 0:\n",
    "        results_O[episode] = 0\n",
    "        results_X[episode] = 0\n",
    "    elif result == 1:\n",
    "        results_O[episode] = 1\n",
    "        results_X[episode] = -1\n",
    "    elif result == 2:\n",
    "        results_O[episode] = -1\n",
    "        results_X[episode] = 1\n",
    "\n",
    "#print(results_O)\n",
    "#print(results_X)\n",
    "\n",
    "cum_results_O = np.cumsum(results_O)\n",
    "cum_results_X = np.cumsum(results_X)\n",
    "\n",
    "#print(cum_results_O)\n",
    "#print(cum_results_X)\n",
    "\n",
    "plt.plot(cum_results_O, color=\"red\", label=\"Player O\")\n",
    "plt.plot(cum_results_X, color=\"blue\", label=\"Player X\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Cumulative reward\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0aae921bb892e1a5feb2970404acf1b6",
     "grade": true,
     "grade_id": "cell-9e4fd5649d4c3263",
     "locked": false,
     "points": 10,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "In a few sentences, discuss your results. Did you expect these results? Why or why not? (We will mark only the first three sentences. Please do not write any longer than that.) \n",
    "\n",
    "The cumulative returns of player O and X are equal and opposite, as expected for Tic-tac-toe which is a zero-sum game. Neither player has a clear advantage as the number of episodes increases because both players are random and who moves first is also random.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2b: Q-learning (20 marks)\n",
    "Use Q-learning to learn an optimal policy for playing Tic-Tac-Toe against a random opponent. Produce a learning curve for your agent. That is, (1) plot average return as a function of episodes, (2) the learning curve should plot the average return of many agents (please specify how many agents you are averaging). \n",
    "\n",
    "For your reference, the pseudo-code for Q-learning is reproduced below from the textbook (Reinforcement Learning, Sutton & Barto, 1998, Section 6.5).\n",
    "<img src=\"images/q_learning.png\" style=\"width: 600px;\"/>\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class Tictactoe_Q():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.players = {\"Q\": 1, \"R\": 2}\n",
    "        self.winners = np.array([\n",
    "            [0, 1, 2], [3, 4, 5], [6, 7, 8],\n",
    "            [0, 3, 6], [1, 4, 7], [2, 5, 8],\n",
    "            [0, 4, 8], [2, 4, 6]\n",
    "            ])\n",
    "        self.board = self.create_board()\n",
    "        self.done = 0\n",
    "\n",
    "    def create_board(self):\n",
    "        return np.zeros(9, dtype=int)\n",
    "\n",
    "    def print_board(self):\n",
    "        b = np.reshape(self.board, (3,3))\n",
    "        print(b)\n",
    "\n",
    "    def get_available_actions(self):\n",
    "        valid_moves = []\n",
    "\n",
    "        for i in range(9):\n",
    "            if self.board[i] == 0:\n",
    "                valid_moves.append(i)\n",
    "        \n",
    "        return valid_moves\n",
    "\n",
    "    def make_move(self, player, move):\n",
    "        piece = self.players[player]\n",
    "        #print(piece)\n",
    "        self.board[move] = piece\n",
    "    \n",
    "    def is_done(self):\n",
    "        return self.done\n",
    "\n",
    "    def check_win(self):\n",
    "        for _, player in self.players.items():\n",
    "            for row in self.winners:\n",
    "                if all([self.board[cell] == player for cell in row]):\n",
    "                    self.done = 1\n",
    "                    return player\n",
    "\n",
    "        for i in range(9):\n",
    "            if self.board[i] == 0:\n",
    "                return None # No one has won yet\n",
    "\n",
    "        # Otherwise, game is a draw\n",
    "        self.done = 1\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tictactoe_Q()\n",
    "t.make_move(\"Q\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEKCAYAAADuEgmxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1170c5048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Use this cell to produce the learning curve for Exercise 2b\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "class RandomAgent():\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def choose_action(self, available_actions):\n",
    "        return random.choice(available_actions)\n",
    "\n",
    "\n",
    "class QLearningAgent():\n",
    "    def __init__(self, alpha, gamma, epsilon):\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.Q = {}\n",
    "        self.prev_state = None\n",
    "        self.prev_q = 0.0\n",
    "        self.prev_state_action = None\n",
    "        \n",
    "    def reset(self):\n",
    "        self.prev_state = None\n",
    "        self.prev_q = 0.0\n",
    "        self.prev_state_action = None\n",
    "    \n",
    "    def choose_action(self, available_actions, state):\n",
    "        self.prev_state = state\n",
    "        \n",
    "        if np.random.uniform(0, 1) < self.epsilon:\n",
    "            action = random.choice(available_actions)\n",
    "            self.prev_q = self.getQ(self.prev_state, action)\n",
    "            self.prev_state_action = (self.prev_state, action)\n",
    "            return action\n",
    "        else:\n",
    "            qs = [self.getQ(state, action) for action in available_actions]\n",
    "            #print(\"qs:\", qs)\n",
    "            maxQ = max(qs)\n",
    "            if qs.count(maxQ) > 1:\n",
    "                best = [i for i in range(len(available_actions)) if qs[i] == maxQ]\n",
    "                i = random.choice(best)\n",
    "            else:\n",
    "                i = qs.index(maxQ)\n",
    "        \n",
    "        action = available_actions[i]\n",
    "        self.prev_q = self.getQ(self.prev_state, action)\n",
    "        self.prev_state_action = (self.prev_state, action)\n",
    "        \n",
    "        return action\n",
    "    \n",
    "    def getQ(self, state, action):\n",
    "        if(self.Q.get((state, action))) is None:\n",
    "            self.Q[(state, action)] = 0.0\n",
    "        return self.Q.get((state,action))\n",
    "    \n",
    "    def updateQ(self, state, reward, available_actions):\n",
    "        qs = []\n",
    "        for action in available_actions:\n",
    "            qs.append(self.getQ(tuple(state), action))\n",
    "        if qs:\n",
    "            max_next_Q = max(qs)\n",
    "        else:\n",
    "            max_next_Q = 0.0\n",
    "        self.Q[self.prev_state_action] = ((1 - self.alpha) * self.prev_q) + (self.alpha * (reward + self.gamma * max_next_Q))\n",
    "\n",
    "alpha = 0.1\n",
    "gamma = 1\n",
    "epsilon = 0.05\n",
    "initial_Q = 0\n",
    "\n",
    "n_episodes = 10000\n",
    "n_agents = 1\n",
    "\n",
    "reward_array = np.zeros(n_episodes)\n",
    "Q_array = []\n",
    "\n",
    "for i in range(n_agents):\n",
    "\n",
    "    random_agent = RandomAgent()\n",
    "    q_agent = QLearningAgent(alpha, gamma, epsilon)\n",
    "\n",
    "    for episode in range(n_episodes):\n",
    "        #print(\"\\nEpisode\\n\")\n",
    "        reward = 0\n",
    "        env = Tictactoe_Q()\n",
    "        players = [\"Q\", \"R\"]\n",
    "        random.shuffle(players)\n",
    "        i = 0\n",
    "        while not env.is_done():\n",
    "            player = players[i % 2]\n",
    "            #print(player, \"'s turn\")\n",
    "            state = env.board\n",
    "            #env.print_board()\n",
    "            available_actions = env.get_available_actions()\n",
    "\n",
    "            if player == \"Q\":\n",
    "                chosen_action = q_agent.choose_action(available_actions, tuple(state))\n",
    "            else:\n",
    "                chosen_action = random_agent.choose_action(available_actions)\n",
    "\n",
    "            env.make_move(player, chosen_action)\n",
    "            winner = env.check_win()\n",
    "            if winner != None:\n",
    "                #print(\"Winner:\", winner)\n",
    "                if winner == 0:\n",
    "                    reward = 0\n",
    "                    reward_array[episode] += 0\n",
    "                elif winner == 1:\n",
    "                    reward = 1\n",
    "                    reward_array[episode] += 1\n",
    "                elif winner == 2:\n",
    "                    reward = -1\n",
    "                    reward_array[episode] += -1\n",
    "                q_agent.updateQ(tuple(state), reward, available_actions)\n",
    "                break\n",
    "            if player == \"Q\":\n",
    "                q_agent.updateQ(tuple(state), reward, available_actions)\n",
    "\n",
    "            i += 1\n",
    "    \n",
    "    Q_array.append(q_agent.Q)\n",
    "\n",
    "#print(reward_array)            \n",
    "\n",
    "cum_reward_array = np.cumsum(reward_array)\n",
    "\n",
    "#print(q_agent.Q)\n",
    "\n",
    "average_returns = np.zeros(n_episodes)\n",
    "for i in range(0, n_episodes):\n",
    "    #print(reward_array[i], cum_reward_array[i])\n",
    "    average_returns[i] = (cum_reward_array[i] / n_agents) / (i + 1)\n",
    "\n",
    "plt.plot(average_returns, color=\"blue\", label=\"Average\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Average return\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "72aafcf5d5929352251f33bf2045b5a5",
     "grade": true,
     "grade_id": "cell-666a718dba214767",
     "locked": false,
     "points": 20,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "In 3 sentences or less, (1) explain the state representation you used, (2) discuss the learning curve you produced. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2c: Optimal policy (20 marks)\n",
    "What is the optimal play for the agent in the following state? You must answer by writing a function that takes a state as input and _prints_ the \"after-state\" that would result from playing an optimal action. The printed output can be primitive but the board has to be somewhat recognizable.   <img src=\"images/tic_tac_toe.png\" style=\"width: 80px;\"/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 0]\n",
      " [0 2 0]\n",
      " [0 1 0]]\n",
      "Action: 2 Value 0.0\n",
      "Action: 3 Value 0.0\n",
      "Action: 5 Value 0.0\n",
      "Action: 6 Value 0.0\n",
      "Action: 7 Value 0.0\n",
      "Action: 8 Value 0.0\n",
      "Action: 0 Value 0.0\n",
      "38578\n",
      "2147\n"
     ]
    }
   ],
   "source": [
    "### You may use this code cell to answer Exercise 2c.\n",
    "\n",
    "def optimal_policy(state):\n",
    "    count1 = 0\n",
    "    count2 = 0\n",
    "    for Q_table in Q_array:\n",
    "    \n",
    "        for key, value in q_agent.Q.items():\n",
    "            count1 += 1\n",
    "            #print(key)\n",
    "            if key[0] == tuple(state):\n",
    "                #print(\"Found\")\n",
    "                print(\"Action:\", key[1], \"Value\", value)\n",
    "            if value > 0:\n",
    "                count2 += 1\n",
    "    #return q_agent.Q[tuple(state)]\n",
    "    print(count1)\n",
    "    print(count2)\n",
    "\n",
    "state = np.array([1, 2, 0, 0, 2, 0, 0, 1, 0])\n",
    "b = np.reshape(state, (3,3))\n",
    "print(b)\n",
    "\n",
    "optimal_policy(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "46351da3e17c7fa3a0c4c0682a8fc786",
     "grade": true,
     "grade_id": "cell-3cd9113829d5b715",
     "locked": false,
     "points": 20,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "Please ignore this cell. We will use this cell to mark your answer. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2d: Sarsa (40 marks)\n",
    "Implement Sarsa to learn how to play Tic-tac-toe against a random player. Produce a learning curve. Also include the learning curve of your previously trained Q-learning agent in the same plot. Discuss the learning curves. For your reference, the pseudo-code for SARSA is reproduced below from the textbook (Reinforcement Learning, Sutton & Barto, 1998, Section 6.4).\n",
    "<img src=\"images/SARSA.png\" style=\"width: 600px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Use this cell to produce the plot for Exercise 2d\n",
    "\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "class RandomAgent():\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def choose_action(self, available_actions):\n",
    "        return random.choice(available_actions)\n",
    "\n",
    "\n",
    "class SarsaAgent():\n",
    "    def __init__(self, alpha, gamma, epsilon):\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.Q = {}\n",
    "        self.prev_state = None\n",
    "        self.prev_q = 0.0\n",
    "        self.prev_state_action = None\n",
    "        \n",
    "    def reset(self):\n",
    "        self.prev_state = None\n",
    "        self.prev_q = 0.0\n",
    "        self.prev_state_action = None\n",
    "    \n",
    "    def choose_action(self, available_actions, state):\n",
    "        self.prev_state = state\n",
    "        \n",
    "        if np.random.uniform(0, 1) < self.epsilon:\n",
    "            action = random.choice(available_actions)\n",
    "            self.prev_q = self.getQ(self.prev_state, action)\n",
    "            self.prev_state_action = (self.prev_state, action)\n",
    "            return action\n",
    "        else:\n",
    "            qs = [self.getQ(state, action) for action in available_actions]\n",
    "            #print(\"qs:\", qs)\n",
    "            maxQ = max(qs)\n",
    "            if qs.count(maxQ) > 1:\n",
    "                best = [i for i in range(len(available_actions)) if qs[i] == maxQ]\n",
    "                i = random.choice(best)\n",
    "            else:\n",
    "                i = qs.index(maxQ)\n",
    "        \n",
    "        action = available_actions[i]\n",
    "        self.prev_q = self.getQ(self.prev_state, action)\n",
    "        self.prev_state_action = (self.prev_state, action)\n",
    "        \n",
    "        return action\n",
    "    \n",
    "    def getQ(self, state, action):\n",
    "        if(self.Q.get((state, action))) is None:\n",
    "            self.Q[(state, action)] = 0.0\n",
    "        return self.Q.get((state,action))\n",
    "    \n",
    "    def updateQ(self, state, reward, available_actions):\n",
    "        qs = []\n",
    "        for action in available_actions:\n",
    "            qs.append(self.getQ(tuple(state), action))\n",
    "        if qs:\n",
    "            max_next_Q = max(qs)\n",
    "        else:\n",
    "            max_next_Q = 0.0\n",
    "        self.Q[self.prev_state_action] = ((1 - self.alpha) * self.prev_q) + (self.alpha * (reward + self.gamma * max_next_Q))\n",
    "\n",
    "alpha = 0.1\n",
    "gamma = 1\n",
    "epsilon = 0.05\n",
    "initial_Q = 0\n",
    "\n",
    "n_episodes = 5000\n",
    "\n",
    "reward_array = np.zeros(n_episodes)\n",
    "Q_array = []\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    random_agent = RandomAgent()\n",
    "    sarsa_agent = SarsaAgent(alpha, gamma, epsilon)\n",
    "\n",
    "    for episode in range(n_episodes):\n",
    "        #print(\"\\nEpisode\\n\")\n",
    "        reward = 0\n",
    "        env = Tictactoe_Q()\n",
    "        players = [\"Q\", \"R\"]\n",
    "        random.shuffle(players)\n",
    "        i = 0\n",
    "        while not env.is_done():\n",
    "            player = players[i % 2]\n",
    "            #print(player, \"'s turn\")\n",
    "            state = env.board\n",
    "            #env.print_board()\n",
    "            available_actions = env.get_available_actions()\n",
    "\n",
    "            if player == \"Q\":\n",
    "                chosen_action = q_agent.choose_action(available_actions, tuple(state))\n",
    "            else:\n",
    "                chosen_action = random_agent.choose_action(available_actions)\n",
    "\n",
    "            env.make_move(player, chosen_action)\n",
    "            winner = env.check_win()\n",
    "            if winner != None:\n",
    "                #print(\"Winner:\", winner)\n",
    "                if winner == 0:\n",
    "                    reward = 0\n",
    "                    reward_array[episode] += 0\n",
    "                elif winner == 1:\n",
    "                    reward = 1\n",
    "                    reward_array[episode] += 1\n",
    "                elif winner == 2:\n",
    "                    reward = -1\n",
    "                    reward_array[episode] += -1\n",
    "        \n",
    "                q_agent.updateQ(tuple(state), reward, available_actions)\n",
    "                \n",
    "            i += 1\n",
    "    \n",
    "    Q_array.append(q_agent.Q)\n",
    "\n",
    "#print(reward_array)            \n",
    "\n",
    "cum_reward_array = np.cumsum(reward_array)\n",
    "\n",
    "#print(q_agent.Q)\n",
    "\n",
    "average_returns = np.zeros(n_episodes)\n",
    "for i in range(0, n_episodes):\n",
    "    average_returns[i] = (cum_reward_array[i] / 10) / (i + 1)\n",
    "\n",
    "plt.plot(average_returns, color=\"blue\", label=\"Average\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Average return\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "5b3cb329a272bc823710306a6bf5ebf2",
     "grade": true,
     "grade_id": "cell-1c1d953aaae5bfb7",
     "locked": false,
     "points": 40,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "Discuss the learning curves here in 10 sentences or less.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
